{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM3/RXhN6rzWBP4acjHcAS6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fofsinx/echo.dataset/blob/data/prepare_transcriptions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "M1pCAbtlnzie",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c6d26ef-d534-4106-837f-2466441c2525"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'echo.dataset'...\n",
            "remote: Enumerating objects: 4647, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 4647 (delta 0), reused 0 (delta 0), pack-reused 4644 (from 1)\u001b[K\n",
            "Receiving objects: 100% (4647/4647), 457.88 MiB | 17.25 MiB/s, done.\n",
            "Resolving deltas: 100% (3/3), done.\n",
            "Updating files: 100% (4639/4639), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/fofsinx/echo.dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faster_whisper pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmmebExEpYkY",
        "outputId": "14084700-9c17-4079-8f0e-871e71fa61db"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faster_whisper\n",
            "  Downloading faster_whisper-1.1.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Collecting ctranslate2<5,>=4.0 (from faster_whisper)\n",
            "  Downloading ctranslate2-4.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.13 in /usr/local/lib/python3.10/dist-packages (from faster_whisper) (0.26.2)\n",
            "Requirement already satisfied: tokenizers<1,>=0.13 in /usr/local/lib/python3.10/dist-packages (from faster_whisper) (0.20.3)\n",
            "Collecting onnxruntime<2,>=1.14 (from faster_whisper)\n",
            "  Downloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting av>=11 (from faster_whisper)\n",
            "  Downloading av-13.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from faster_whisper) (4.66.6)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from ctranslate2<5,>=4.0->faster_whisper) (75.1.0)\n",
            "Requirement already satisfied: pyyaml<7,>=5.3 in /usr/local/lib/python3.10/dist-packages (from ctranslate2<5,>=4.0->faster_whisper) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster_whisper) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster_whisper) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster_whisper) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster_whisper) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster_whisper) (4.12.2)\n",
            "Collecting coloredlogs (from onnxruntime<2,>=1.14->faster_whisper)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster_whisper) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster_whisper) (4.25.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster_whisper) (1.13.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime<2,>=1.14->faster_whisper)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13->faster_whisper) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13->faster_whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13->faster_whisper) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13->faster_whisper) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime<2,>=1.14->faster_whisper) (1.3.0)\n",
            "Downloading faster_whisper-1.1.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading av-13.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.1/33.1 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ctranslate2-4.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m85.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: humanfriendly, ctranslate2, av, coloredlogs, onnxruntime, faster_whisper\n",
            "Successfully installed av-13.1.0 coloredlogs-15.0.1 ctranslate2-4.5.0 faster_whisper-1.1.0 humanfriendly-10.0 onnxruntime-1.20.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import uuid\n",
        "import csv\n",
        "import concurrent.futures\n",
        "from faster_whisper import WhisperModel\n",
        "import pandas as pd\n",
        "import logging\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Initialize Whisper model with GPU\n",
        "model = WhisperModel(\"large-v3\", device=\"mps\", compute_type=\"float16\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKEAeOXlpc9A",
        "outputId": "d1f5cb60-feb5-49c5-919e-f9969ce2fccf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def transcribe_audio(row):\n",
        "    \"\"\"Transcribe a single audio file using Whisper model\"\"\"\n",
        "    try:\n",
        "        logger.info(f\"🎯 File: prepare.py, Line: 16, Function: transcribe_audio, Processing file: {row['path']}\")\n",
        "        segments, _ = model.transcribe(row['path'])\n",
        "        transcription = \" \".join([segment.text for segment in segments])\n",
        "        return {\n",
        "            'id': row['id'],\n",
        "            'path': row['path'],\n",
        "            'transcription': transcription\n",
        "        }\n",
        "    except Exception as e:\n",
        "        logger.error(f\"❌ Error processing {row['path']}: {str(e)}\")\n",
        "        return {\n",
        "            'id': row['id'],\n",
        "            'path': row['path'],\n",
        "            'transcription': ''\n",
        "        }\n",
        "\n",
        "def process_csv_file(csv_path, base_path):\n",
        "    \"\"\"Process a CSV file and add transcriptions\"\"\"\n",
        "    try:\n",
        "        # Read CSV file\n",
        "        df = pd.read_csv(csv_path)\n",
        "        logger.info(f\"📊 File: prepare.py, Line: 35, Function: process_csv_file, Processing CSV: {csv_path}\")\n",
        "\n",
        "        # Create ThreadPoolExecutor for parallel processing\n",
        "        with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n",
        "            # Process each row in parallel\n",
        "            # Add base path to each record\n",
        "            records = df.to_dict('records')\n",
        "            for record in records:\n",
        "                record['path'] = f\"{base_path}/{record['path']}\"\n",
        "            results = list(executor.map(transcribe_audio, records))\n",
        "\n",
        "        # Create new DataFrame with results\n",
        "        new_df = pd.DataFrame(results)\n",
        "\n",
        "        # Save back to CSV\n",
        "        new_df.to_csv(csv_path, index=False)\n",
        "        logger.info(f\"✅ Successfully processed {csv_path}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"❌ Error processing CSV {csv_path}: {str(e)}\")\n",
        "\n",
        "def get_folders(parent_path):\n",
        "    return [os.path.join(parent_path, f) for f in os.listdir(parent_path) if os.path.isdir(os.path.join(parent_path, f))]\n",
        "\n",
        "def create_csv_for_folder(folder_path):\n",
        "    folder_name = os.path.basename(folder_path.rstrip(\"/\"))\n",
        "    csv_filename = f\"{folder_name}_dataset.csv\"\n",
        "\n",
        "    data = []\n",
        "    for file in os.listdir(folder_path):\n",
        "        file_path = os.path.join(folder_path, file)\n",
        "        if os.path.isfile(file_path):\n",
        "            data.append({\"id\": str(uuid.uuid4()), \"path\": file_path})\n",
        "\n",
        "    with open(csv_filename, mode=\"w\", newline=\"\") as csvfile:\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=[\"id\", \"path\"])\n",
        "        writer.writeheader()\n",
        "        writer.writerows(data)\n",
        "\n",
        "    logger.info(f\"📝 Created CSV for folder '{folder_name}': {csv_filename}\")\n",
        "\n",
        "    # Process the newly created CSV to add transcriptions\n",
        "    process_csv_file(csv_filename)\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    folders = [\n",
        "        'vale',\n",
        "        'maple',\n",
        "        'glimmer',\n",
        "        'juniper'\n",
        "    ]\n",
        "    base_path = \"echo.dataset\"\n",
        "    for folder in folders:\n",
        "        process_csv_file(os.path.join(base_path, folder, f\"{folder}_dataset.csv\"), os.path.join(base_path, folder))"
      ],
      "metadata": {
        "id": "OO7FeErnpikt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}